{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_pytorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ghvie2ZHupz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#From : https://github.com/pytorch/examples/blob/master/vae/main.py\n",
        "\n",
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbHlbFavH9KW",
        "colab_type": "code",
        "outputId": "d5ee28fd-41a8-4776-fbbb-bdfa19bdea14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "device = \"cuda\"\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "datasets.MNIST('/', train = True, download = True,\n",
        "              transform = transforms.ToTensor()),\n",
        "    batch_size = 128, shuffle = True, **kwargs\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "datasets.MNIST('/', train = False, download = True,\n",
        "              transform = transforms.ToTensor()),\n",
        "    batch_size = 128, shuffle = True, **kwargs\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:01, 6300710.01it/s]                             \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 275355.37it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting /MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 4766188.82it/s]                           \n",
            "8192it [00:00, 130415.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting /MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5lJSImOIH6F",
        "colab_type": "text"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8vKHizIIKN1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.fc1 = nn.Linear(784, 400)\n",
        "        self.fc21 = nn.Linear(400, 20)\n",
        "        self.fc22 = nn.Linear(400, 20)\n",
        "        self.fc3 = nn.Linear(20, 400)\n",
        "        self.fc4 = nn.Linear(400, 784)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return  self.fc21(h1), self.fc22(h1)\n",
        "    \n",
        "    def reparameterize(self, mu, logvar): #https://www.quora.com/What-is-the-reparameterization-trick-in-variational-autoencoders/answer/Daniel-L%C3%A9vy\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "    \n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 784))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "      \n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDMcCQjdKOCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JRZAjVgQiI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSbPAdVYQsqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jt7fq1QeSfrU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                      recon_batch.view(batch_size, 1, 28, 28)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                         'reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvNIviq-SqZc",
        "colab_type": "code",
        "outputId": "fdc1df06-ca3f-42b1-e88e-0850b9f9f1f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 8857
        }
      },
      "source": [
        "  epochs = 20\n",
        "  for epoch in range(1, epochs + 1):\n",
        "        train(epoch)\n",
        "        test(epoch)\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(64, 20).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "            save_image(sample.view(64, 1, 28, 28),\n",
        "                       'sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 549.444946\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 237.495834\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 215.466019\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 198.516693\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 195.461823\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 186.745728\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 170.829422\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 163.038956\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 166.517609\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 150.477417\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 149.881927\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 152.486679\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 152.520584\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 139.888123\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 145.824341\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 141.768066\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 142.069504\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 133.177368\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 130.572830\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 137.206512\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 129.651184\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 128.711472\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 131.912109\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 131.649033\n",
            "====> Epoch: 1 Average loss: 164.7653\n",
            "====> Test set loss: 127.5125\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 129.149521\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 135.851807\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 122.659103\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 119.722801\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 126.731529\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 125.756508\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 129.614349\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 122.607513\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 123.860550\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 126.460991\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 120.899612\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 120.242622\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 120.450150\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 115.564545\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 118.379593\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 123.352501\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 115.869965\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 117.925217\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 118.092789\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 120.340157\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 120.227280\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 118.129471\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 115.027557\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 118.368790\n",
            "====> Epoch: 2 Average loss: 121.5136\n",
            "====> Test set loss: 115.6247\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 116.416664\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 119.307205\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 111.809967\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 120.838524\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 117.607651\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 114.735985\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 115.932701\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 114.465042\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 118.237846\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 112.969955\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 115.004494\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 116.019623\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 114.830078\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 110.789742\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 116.832413\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 112.402695\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 113.770599\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 110.494370\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 110.915161\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 111.452194\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 112.005135\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 113.955490\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 112.165695\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 115.301033\n",
            "====> Epoch: 3 Average loss: 114.4310\n",
            "====> Test set loss: 111.5649\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 115.013405\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 112.668320\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 114.508949\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 108.787544\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 112.873856\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 118.561089\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 108.982033\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 106.189789\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 106.748062\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 114.714325\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 108.029366\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 113.175377\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 109.168747\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 115.361816\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 110.207237\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 110.028137\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 114.432983\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 113.448792\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 110.514999\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 112.811111\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 109.010262\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 110.326508\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 107.954041\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 110.319229\n",
            "====> Epoch: 4 Average loss: 111.4867\n",
            "====> Test set loss: 109.9136\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 111.588600\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 108.626648\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 113.439621\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 111.430748\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 113.221451\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 114.324066\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 111.913475\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 105.941818\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 106.471191\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 111.087189\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 109.717262\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 110.509834\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 110.931198\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 109.466431\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 115.148834\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 106.657852\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 109.550499\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 103.756851\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 105.101196\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 113.120071\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 107.981339\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 111.487198\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 113.548615\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 110.090607\n",
            "====> Epoch: 5 Average loss: 109.7891\n",
            "====> Test set loss: 108.6167\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 112.322838\n",
            "Train Epoch: 6 [2560/60000 (4%)]\tLoss: 111.145065\n",
            "Train Epoch: 6 [5120/60000 (9%)]\tLoss: 105.946472\n",
            "Train Epoch: 6 [7680/60000 (13%)]\tLoss: 109.247925\n",
            "Train Epoch: 6 [10240/60000 (17%)]\tLoss: 109.208397\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 108.784470\n",
            "Train Epoch: 6 [15360/60000 (26%)]\tLoss: 106.959320\n",
            "Train Epoch: 6 [17920/60000 (30%)]\tLoss: 110.663780\n",
            "Train Epoch: 6 [20480/60000 (34%)]\tLoss: 110.801346\n",
            "Train Epoch: 6 [23040/60000 (38%)]\tLoss: 111.077621\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 112.798393\n",
            "Train Epoch: 6 [28160/60000 (47%)]\tLoss: 107.717682\n",
            "Train Epoch: 6 [30720/60000 (51%)]\tLoss: 106.842422\n",
            "Train Epoch: 6 [33280/60000 (55%)]\tLoss: 108.610680\n",
            "Train Epoch: 6 [35840/60000 (60%)]\tLoss: 108.456306\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 108.211243\n",
            "Train Epoch: 6 [40960/60000 (68%)]\tLoss: 106.265976\n",
            "Train Epoch: 6 [43520/60000 (72%)]\tLoss: 112.288719\n",
            "Train Epoch: 6 [46080/60000 (77%)]\tLoss: 108.690666\n",
            "Train Epoch: 6 [48640/60000 (81%)]\tLoss: 104.388123\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 110.230942\n",
            "Train Epoch: 6 [53760/60000 (90%)]\tLoss: 109.884506\n",
            "Train Epoch: 6 [56320/60000 (94%)]\tLoss: 109.151917\n",
            "Train Epoch: 6 [58880/60000 (98%)]\tLoss: 107.976349\n",
            "====> Epoch: 6 Average loss: 108.6161\n",
            "====> Test set loss: 107.8186\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 105.695618\n",
            "Train Epoch: 7 [2560/60000 (4%)]\tLoss: 109.372055\n",
            "Train Epoch: 7 [5120/60000 (9%)]\tLoss: 110.806458\n",
            "Train Epoch: 7 [7680/60000 (13%)]\tLoss: 109.430748\n",
            "Train Epoch: 7 [10240/60000 (17%)]\tLoss: 109.039314\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 108.625648\n",
            "Train Epoch: 7 [15360/60000 (26%)]\tLoss: 108.364304\n",
            "Train Epoch: 7 [17920/60000 (30%)]\tLoss: 110.280594\n",
            "Train Epoch: 7 [20480/60000 (34%)]\tLoss: 107.662521\n",
            "Train Epoch: 7 [23040/60000 (38%)]\tLoss: 108.105705\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 111.217255\n",
            "Train Epoch: 7 [28160/60000 (47%)]\tLoss: 104.088951\n",
            "Train Epoch: 7 [30720/60000 (51%)]\tLoss: 104.164993\n",
            "Train Epoch: 7 [33280/60000 (55%)]\tLoss: 104.273224\n",
            "Train Epoch: 7 [35840/60000 (60%)]\tLoss: 109.490753\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 106.930878\n",
            "Train Epoch: 7 [40960/60000 (68%)]\tLoss: 108.259453\n",
            "Train Epoch: 7 [43520/60000 (72%)]\tLoss: 107.768951\n",
            "Train Epoch: 7 [46080/60000 (77%)]\tLoss: 103.649475\n",
            "Train Epoch: 7 [48640/60000 (81%)]\tLoss: 107.631760\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 108.558632\n",
            "Train Epoch: 7 [53760/60000 (90%)]\tLoss: 109.200356\n",
            "Train Epoch: 7 [56320/60000 (94%)]\tLoss: 108.491211\n",
            "Train Epoch: 7 [58880/60000 (98%)]\tLoss: 107.076614\n",
            "====> Epoch: 7 Average loss: 107.8318\n",
            "====> Test set loss: 106.9796\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 106.165771\n",
            "Train Epoch: 8 [2560/60000 (4%)]\tLoss: 103.011482\n",
            "Train Epoch: 8 [5120/60000 (9%)]\tLoss: 105.606949\n",
            "Train Epoch: 8 [7680/60000 (13%)]\tLoss: 107.538055\n",
            "Train Epoch: 8 [10240/60000 (17%)]\tLoss: 102.146271\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 107.641144\n",
            "Train Epoch: 8 [15360/60000 (26%)]\tLoss: 111.556122\n",
            "Train Epoch: 8 [17920/60000 (30%)]\tLoss: 106.104462\n",
            "Train Epoch: 8 [20480/60000 (34%)]\tLoss: 103.734604\n",
            "Train Epoch: 8 [23040/60000 (38%)]\tLoss: 106.394318\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 107.070747\n",
            "Train Epoch: 8 [28160/60000 (47%)]\tLoss: 107.368515\n",
            "Train Epoch: 8 [30720/60000 (51%)]\tLoss: 109.876778\n",
            "Train Epoch: 8 [33280/60000 (55%)]\tLoss: 103.944992\n",
            "Train Epoch: 8 [35840/60000 (60%)]\tLoss: 107.562820\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 107.018951\n",
            "Train Epoch: 8 [40960/60000 (68%)]\tLoss: 108.571251\n",
            "Train Epoch: 8 [43520/60000 (72%)]\tLoss: 105.427032\n",
            "Train Epoch: 8 [46080/60000 (77%)]\tLoss: 105.325050\n",
            "Train Epoch: 8 [48640/60000 (81%)]\tLoss: 105.619949\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 109.614059\n",
            "Train Epoch: 8 [53760/60000 (90%)]\tLoss: 109.117538\n",
            "Train Epoch: 8 [56320/60000 (94%)]\tLoss: 107.993149\n",
            "Train Epoch: 8 [58880/60000 (98%)]\tLoss: 102.836906\n",
            "====> Epoch: 8 Average loss: 107.1923\n",
            "====> Test set loss: 106.5409\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 106.237625\n",
            "Train Epoch: 9 [2560/60000 (4%)]\tLoss: 110.542313\n",
            "Train Epoch: 9 [5120/60000 (9%)]\tLoss: 103.373665\n",
            "Train Epoch: 9 [7680/60000 (13%)]\tLoss: 108.850441\n",
            "Train Epoch: 9 [10240/60000 (17%)]\tLoss: 102.968735\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 108.869446\n",
            "Train Epoch: 9 [15360/60000 (26%)]\tLoss: 102.653572\n",
            "Train Epoch: 9 [17920/60000 (30%)]\tLoss: 108.428429\n",
            "Train Epoch: 9 [20480/60000 (34%)]\tLoss: 108.758957\n",
            "Train Epoch: 9 [23040/60000 (38%)]\tLoss: 102.403595\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 106.200485\n",
            "Train Epoch: 9 [28160/60000 (47%)]\tLoss: 108.237106\n",
            "Train Epoch: 9 [30720/60000 (51%)]\tLoss: 107.511490\n",
            "Train Epoch: 9 [33280/60000 (55%)]\tLoss: 109.031639\n",
            "Train Epoch: 9 [35840/60000 (60%)]\tLoss: 104.723389\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 108.584122\n",
            "Train Epoch: 9 [40960/60000 (68%)]\tLoss: 107.596802\n",
            "Train Epoch: 9 [43520/60000 (72%)]\tLoss: 106.313751\n",
            "Train Epoch: 9 [46080/60000 (77%)]\tLoss: 106.095444\n",
            "Train Epoch: 9 [48640/60000 (81%)]\tLoss: 106.640923\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 107.792244\n",
            "Train Epoch: 9 [53760/60000 (90%)]\tLoss: 107.558975\n",
            "Train Epoch: 9 [56320/60000 (94%)]\tLoss: 107.020256\n",
            "Train Epoch: 9 [58880/60000 (98%)]\tLoss: 105.099319\n",
            "====> Epoch: 9 Average loss: 106.6943\n",
            "====> Test set loss: 106.0860\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 101.855026\n",
            "Train Epoch: 10 [2560/60000 (4%)]\tLoss: 104.294281\n",
            "Train Epoch: 10 [5120/60000 (9%)]\tLoss: 108.672997\n",
            "Train Epoch: 10 [7680/60000 (13%)]\tLoss: 109.640198\n",
            "Train Epoch: 10 [10240/60000 (17%)]\tLoss: 111.800598\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 104.549652\n",
            "Train Epoch: 10 [15360/60000 (26%)]\tLoss: 105.429245\n",
            "Train Epoch: 10 [17920/60000 (30%)]\tLoss: 104.681122\n",
            "Train Epoch: 10 [20480/60000 (34%)]\tLoss: 108.375656\n",
            "Train Epoch: 10 [23040/60000 (38%)]\tLoss: 108.915497\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 107.146996\n",
            "Train Epoch: 10 [28160/60000 (47%)]\tLoss: 107.941589\n",
            "Train Epoch: 10 [30720/60000 (51%)]\tLoss: 104.327766\n",
            "Train Epoch: 10 [33280/60000 (55%)]\tLoss: 105.338676\n",
            "Train Epoch: 10 [35840/60000 (60%)]\tLoss: 105.748230\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 106.066071\n",
            "Train Epoch: 10 [40960/60000 (68%)]\tLoss: 109.703781\n",
            "Train Epoch: 10 [43520/60000 (72%)]\tLoss: 107.191467\n",
            "Train Epoch: 10 [46080/60000 (77%)]\tLoss: 108.047188\n",
            "Train Epoch: 10 [48640/60000 (81%)]\tLoss: 100.009033\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 104.768593\n",
            "Train Epoch: 10 [53760/60000 (90%)]\tLoss: 105.502625\n",
            "Train Epoch: 10 [56320/60000 (94%)]\tLoss: 107.476822\n",
            "Train Epoch: 10 [58880/60000 (98%)]\tLoss: 104.277222\n",
            "====> Epoch: 10 Average loss: 106.2616\n",
            "====> Test set loss: 105.6515\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 108.285210\n",
            "Train Epoch: 11 [2560/60000 (4%)]\tLoss: 106.283585\n",
            "Train Epoch: 11 [5120/60000 (9%)]\tLoss: 107.662460\n",
            "Train Epoch: 11 [7680/60000 (13%)]\tLoss: 105.292671\n",
            "Train Epoch: 11 [10240/60000 (17%)]\tLoss: 102.354301\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 103.689285\n",
            "Train Epoch: 11 [15360/60000 (26%)]\tLoss: 107.124390\n",
            "Train Epoch: 11 [17920/60000 (30%)]\tLoss: 102.440887\n",
            "Train Epoch: 11 [20480/60000 (34%)]\tLoss: 108.460693\n",
            "Train Epoch: 11 [23040/60000 (38%)]\tLoss: 107.259834\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 105.707321\n",
            "Train Epoch: 11 [28160/60000 (47%)]\tLoss: 105.815872\n",
            "Train Epoch: 11 [30720/60000 (51%)]\tLoss: 103.092323\n",
            "Train Epoch: 11 [33280/60000 (55%)]\tLoss: 110.139267\n",
            "Train Epoch: 11 [35840/60000 (60%)]\tLoss: 103.849556\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 106.658203\n",
            "Train Epoch: 11 [40960/60000 (68%)]\tLoss: 101.223267\n",
            "Train Epoch: 11 [43520/60000 (72%)]\tLoss: 102.893456\n",
            "Train Epoch: 11 [46080/60000 (77%)]\tLoss: 102.288910\n",
            "Train Epoch: 11 [48640/60000 (81%)]\tLoss: 106.241142\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 105.604683\n",
            "Train Epoch: 11 [53760/60000 (90%)]\tLoss: 106.805687\n",
            "Train Epoch: 11 [56320/60000 (94%)]\tLoss: 107.498184\n",
            "Train Epoch: 11 [58880/60000 (98%)]\tLoss: 106.033913\n",
            "====> Epoch: 11 Average loss: 105.8746\n",
            "====> Test set loss: 105.2798\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 104.988091\n",
            "Train Epoch: 12 [2560/60000 (4%)]\tLoss: 108.987679\n",
            "Train Epoch: 12 [5120/60000 (9%)]\tLoss: 106.798851\n",
            "Train Epoch: 12 [7680/60000 (13%)]\tLoss: 107.131866\n",
            "Train Epoch: 12 [10240/60000 (17%)]\tLoss: 106.127884\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 108.772865\n",
            "Train Epoch: 12 [15360/60000 (26%)]\tLoss: 100.536240\n",
            "Train Epoch: 12 [17920/60000 (30%)]\tLoss: 103.631317\n",
            "Train Epoch: 12 [20480/60000 (34%)]\tLoss: 104.153786\n",
            "Train Epoch: 12 [23040/60000 (38%)]\tLoss: 106.200470\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 104.936096\n",
            "Train Epoch: 12 [28160/60000 (47%)]\tLoss: 104.221939\n",
            "Train Epoch: 12 [30720/60000 (51%)]\tLoss: 102.952026\n",
            "Train Epoch: 12 [33280/60000 (55%)]\tLoss: 104.025002\n",
            "Train Epoch: 12 [35840/60000 (60%)]\tLoss: 110.087448\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 107.680817\n",
            "Train Epoch: 12 [40960/60000 (68%)]\tLoss: 106.749222\n",
            "Train Epoch: 12 [43520/60000 (72%)]\tLoss: 105.190552\n",
            "Train Epoch: 12 [46080/60000 (77%)]\tLoss: 105.516846\n",
            "Train Epoch: 12 [48640/60000 (81%)]\tLoss: 99.043388\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 102.490608\n",
            "Train Epoch: 12 [53760/60000 (90%)]\tLoss: 105.936722\n",
            "Train Epoch: 12 [56320/60000 (94%)]\tLoss: 103.179619\n",
            "Train Epoch: 12 [58880/60000 (98%)]\tLoss: 102.020401\n",
            "====> Epoch: 12 Average loss: 105.6051\n",
            "====> Test set loss: 105.2850\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 103.437309\n",
            "Train Epoch: 13 [2560/60000 (4%)]\tLoss: 104.351105\n",
            "Train Epoch: 13 [5120/60000 (9%)]\tLoss: 104.673569\n",
            "Train Epoch: 13 [7680/60000 (13%)]\tLoss: 109.178566\n",
            "Train Epoch: 13 [10240/60000 (17%)]\tLoss: 106.756149\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 105.576637\n",
            "Train Epoch: 13 [15360/60000 (26%)]\tLoss: 108.612526\n",
            "Train Epoch: 13 [17920/60000 (30%)]\tLoss: 108.051056\n",
            "Train Epoch: 13 [20480/60000 (34%)]\tLoss: 103.648582\n",
            "Train Epoch: 13 [23040/60000 (38%)]\tLoss: 106.363914\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 103.442780\n",
            "Train Epoch: 13 [28160/60000 (47%)]\tLoss: 107.136497\n",
            "Train Epoch: 13 [30720/60000 (51%)]\tLoss: 106.740028\n",
            "Train Epoch: 13 [33280/60000 (55%)]\tLoss: 104.578796\n",
            "Train Epoch: 13 [35840/60000 (60%)]\tLoss: 105.129639\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 104.451912\n",
            "Train Epoch: 13 [40960/60000 (68%)]\tLoss: 106.296738\n",
            "Train Epoch: 13 [43520/60000 (72%)]\tLoss: 103.548569\n",
            "Train Epoch: 13 [46080/60000 (77%)]\tLoss: 103.419052\n",
            "Train Epoch: 13 [48640/60000 (81%)]\tLoss: 101.368752\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 105.306480\n",
            "Train Epoch: 13 [53760/60000 (90%)]\tLoss: 107.907425\n",
            "Train Epoch: 13 [56320/60000 (94%)]\tLoss: 105.805244\n",
            "Train Epoch: 13 [58880/60000 (98%)]\tLoss: 108.384064\n",
            "====> Epoch: 13 Average loss: 105.3344\n",
            "====> Test set loss: 105.0316\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 108.516525\n",
            "Train Epoch: 14 [2560/60000 (4%)]\tLoss: 104.443825\n",
            "Train Epoch: 14 [5120/60000 (9%)]\tLoss: 103.490982\n",
            "Train Epoch: 14 [7680/60000 (13%)]\tLoss: 105.531021\n",
            "Train Epoch: 14 [10240/60000 (17%)]\tLoss: 109.017761\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 104.341194\n",
            "Train Epoch: 14 [15360/60000 (26%)]\tLoss: 99.438461\n",
            "Train Epoch: 14 [17920/60000 (30%)]\tLoss: 105.160706\n",
            "Train Epoch: 14 [20480/60000 (34%)]\tLoss: 103.807358\n",
            "Train Epoch: 14 [23040/60000 (38%)]\tLoss: 101.839981\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 105.585953\n",
            "Train Epoch: 14 [28160/60000 (47%)]\tLoss: 102.725800\n",
            "Train Epoch: 14 [30720/60000 (51%)]\tLoss: 108.727402\n",
            "Train Epoch: 14 [33280/60000 (55%)]\tLoss: 106.078445\n",
            "Train Epoch: 14 [35840/60000 (60%)]\tLoss: 109.729828\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 105.842422\n",
            "Train Epoch: 14 [40960/60000 (68%)]\tLoss: 105.554680\n",
            "Train Epoch: 14 [43520/60000 (72%)]\tLoss: 105.069946\n",
            "Train Epoch: 14 [46080/60000 (77%)]\tLoss: 111.292343\n",
            "Train Epoch: 14 [48640/60000 (81%)]\tLoss: 103.544891\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 102.349045\n",
            "Train Epoch: 14 [53760/60000 (90%)]\tLoss: 106.581711\n",
            "Train Epoch: 14 [56320/60000 (94%)]\tLoss: 104.302826\n",
            "Train Epoch: 14 [58880/60000 (98%)]\tLoss: 110.283508\n",
            "====> Epoch: 14 Average loss: 105.1031\n",
            "====> Test set loss: 104.7227\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 106.313293\n",
            "Train Epoch: 15 [2560/60000 (4%)]\tLoss: 104.994804\n",
            "Train Epoch: 15 [5120/60000 (9%)]\tLoss: 106.373871\n",
            "Train Epoch: 15 [7680/60000 (13%)]\tLoss: 105.704735\n",
            "Train Epoch: 15 [10240/60000 (17%)]\tLoss: 98.987076\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 104.818527\n",
            "Train Epoch: 15 [15360/60000 (26%)]\tLoss: 103.204849\n",
            "Train Epoch: 15 [17920/60000 (30%)]\tLoss: 107.424980\n",
            "Train Epoch: 15 [20480/60000 (34%)]\tLoss: 101.308662\n",
            "Train Epoch: 15 [23040/60000 (38%)]\tLoss: 105.487961\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 105.425491\n",
            "Train Epoch: 15 [28160/60000 (47%)]\tLoss: 108.216515\n",
            "Train Epoch: 15 [30720/60000 (51%)]\tLoss: 105.675735\n",
            "Train Epoch: 15 [33280/60000 (55%)]\tLoss: 100.086716\n",
            "Train Epoch: 15 [35840/60000 (60%)]\tLoss: 102.621071\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 105.737854\n",
            "Train Epoch: 15 [40960/60000 (68%)]\tLoss: 103.860245\n",
            "Train Epoch: 15 [43520/60000 (72%)]\tLoss: 103.078690\n",
            "Train Epoch: 15 [46080/60000 (77%)]\tLoss: 108.103104\n",
            "Train Epoch: 15 [48640/60000 (81%)]\tLoss: 105.259293\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 102.059921\n",
            "Train Epoch: 15 [53760/60000 (90%)]\tLoss: 103.524231\n",
            "Train Epoch: 15 [56320/60000 (94%)]\tLoss: 105.740242\n",
            "Train Epoch: 15 [58880/60000 (98%)]\tLoss: 103.822784\n",
            "====> Epoch: 15 Average loss: 104.8542\n",
            "====> Test set loss: 104.2645\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 100.844254\n",
            "Train Epoch: 16 [2560/60000 (4%)]\tLoss: 109.630112\n",
            "Train Epoch: 16 [5120/60000 (9%)]\tLoss: 105.066582\n",
            "Train Epoch: 16 [7680/60000 (13%)]\tLoss: 105.198708\n",
            "Train Epoch: 16 [10240/60000 (17%)]\tLoss: 102.109909\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 102.395676\n",
            "Train Epoch: 16 [15360/60000 (26%)]\tLoss: 103.431618\n",
            "Train Epoch: 16 [17920/60000 (30%)]\tLoss: 104.370010\n",
            "Train Epoch: 16 [20480/60000 (34%)]\tLoss: 100.447731\n",
            "Train Epoch: 16 [23040/60000 (38%)]\tLoss: 103.740250\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 104.719727\n",
            "Train Epoch: 16 [28160/60000 (47%)]\tLoss: 105.859528\n",
            "Train Epoch: 16 [30720/60000 (51%)]\tLoss: 104.199554\n",
            "Train Epoch: 16 [33280/60000 (55%)]\tLoss: 98.885689\n",
            "Train Epoch: 16 [35840/60000 (60%)]\tLoss: 103.606926\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 107.394592\n",
            "Train Epoch: 16 [40960/60000 (68%)]\tLoss: 103.230347\n",
            "Train Epoch: 16 [43520/60000 (72%)]\tLoss: 107.663132\n",
            "Train Epoch: 16 [46080/60000 (77%)]\tLoss: 107.061890\n",
            "Train Epoch: 16 [48640/60000 (81%)]\tLoss: 103.794243\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 107.714516\n",
            "Train Epoch: 16 [53760/60000 (90%)]\tLoss: 102.009918\n",
            "Train Epoch: 16 [56320/60000 (94%)]\tLoss: 107.396912\n",
            "Train Epoch: 16 [58880/60000 (98%)]\tLoss: 99.863266\n",
            "====> Epoch: 16 Average loss: 104.6633\n",
            "====> Test set loss: 104.2294\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 103.217346\n",
            "Train Epoch: 17 [2560/60000 (4%)]\tLoss: 105.134811\n",
            "Train Epoch: 17 [5120/60000 (9%)]\tLoss: 103.860260\n",
            "Train Epoch: 17 [7680/60000 (13%)]\tLoss: 102.477821\n",
            "Train Epoch: 17 [10240/60000 (17%)]\tLoss: 104.901428\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 105.017700\n",
            "Train Epoch: 17 [15360/60000 (26%)]\tLoss: 102.738068\n",
            "Train Epoch: 17 [17920/60000 (30%)]\tLoss: 103.221931\n",
            "Train Epoch: 17 [20480/60000 (34%)]\tLoss: 104.727432\n",
            "Train Epoch: 17 [23040/60000 (38%)]\tLoss: 105.624924\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 104.461090\n",
            "Train Epoch: 17 [28160/60000 (47%)]\tLoss: 101.586128\n",
            "Train Epoch: 17 [30720/60000 (51%)]\tLoss: 102.157166\n",
            "Train Epoch: 17 [33280/60000 (55%)]\tLoss: 106.172974\n",
            "Train Epoch: 17 [35840/60000 (60%)]\tLoss: 105.693108\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 101.682396\n",
            "Train Epoch: 17 [40960/60000 (68%)]\tLoss: 103.347763\n",
            "Train Epoch: 17 [43520/60000 (72%)]\tLoss: 108.118790\n",
            "Train Epoch: 17 [46080/60000 (77%)]\tLoss: 104.791809\n",
            "Train Epoch: 17 [48640/60000 (81%)]\tLoss: 107.639130\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 104.251526\n",
            "Train Epoch: 17 [53760/60000 (90%)]\tLoss: 102.237480\n",
            "Train Epoch: 17 [56320/60000 (94%)]\tLoss: 106.689331\n",
            "Train Epoch: 17 [58880/60000 (98%)]\tLoss: 100.192276\n",
            "====> Epoch: 17 Average loss: 104.5326\n",
            "====> Test set loss: 104.0920\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 103.154083\n",
            "Train Epoch: 18 [2560/60000 (4%)]\tLoss: 105.935287\n",
            "Train Epoch: 18 [5120/60000 (9%)]\tLoss: 105.383499\n",
            "Train Epoch: 18 [7680/60000 (13%)]\tLoss: 102.993675\n",
            "Train Epoch: 18 [10240/60000 (17%)]\tLoss: 106.500305\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 105.167831\n",
            "Train Epoch: 18 [15360/60000 (26%)]\tLoss: 104.434654\n",
            "Train Epoch: 18 [17920/60000 (30%)]\tLoss: 100.688683\n",
            "Train Epoch: 18 [20480/60000 (34%)]\tLoss: 106.232040\n",
            "Train Epoch: 18 [23040/60000 (38%)]\tLoss: 101.332336\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 100.465836\n",
            "Train Epoch: 18 [28160/60000 (47%)]\tLoss: 102.547012\n",
            "Train Epoch: 18 [30720/60000 (51%)]\tLoss: 101.935776\n",
            "Train Epoch: 18 [33280/60000 (55%)]\tLoss: 103.125687\n",
            "Train Epoch: 18 [35840/60000 (60%)]\tLoss: 105.713684\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 104.680222\n",
            "Train Epoch: 18 [40960/60000 (68%)]\tLoss: 107.036316\n",
            "Train Epoch: 18 [43520/60000 (72%)]\tLoss: 106.812592\n",
            "Train Epoch: 18 [46080/60000 (77%)]\tLoss: 104.929749\n",
            "Train Epoch: 18 [48640/60000 (81%)]\tLoss: 104.180107\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 103.125092\n",
            "Train Epoch: 18 [53760/60000 (90%)]\tLoss: 103.182465\n",
            "Train Epoch: 18 [56320/60000 (94%)]\tLoss: 101.972801\n",
            "Train Epoch: 18 [58880/60000 (98%)]\tLoss: 98.217415\n",
            "====> Epoch: 18 Average loss: 104.3210\n",
            "====> Test set loss: 104.0435\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 103.871613\n",
            "Train Epoch: 19 [2560/60000 (4%)]\tLoss: 107.331795\n",
            "Train Epoch: 19 [5120/60000 (9%)]\tLoss: 108.677750\n",
            "Train Epoch: 19 [7680/60000 (13%)]\tLoss: 104.367783\n",
            "Train Epoch: 19 [10240/60000 (17%)]\tLoss: 107.511093\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 105.598038\n",
            "Train Epoch: 19 [15360/60000 (26%)]\tLoss: 105.001678\n",
            "Train Epoch: 19 [17920/60000 (30%)]\tLoss: 103.464233\n",
            "Train Epoch: 19 [20480/60000 (34%)]\tLoss: 103.464630\n",
            "Train Epoch: 19 [23040/60000 (38%)]\tLoss: 106.329224\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 103.162598\n",
            "Train Epoch: 19 [28160/60000 (47%)]\tLoss: 101.964317\n",
            "Train Epoch: 19 [30720/60000 (51%)]\tLoss: 106.080627\n",
            "Train Epoch: 19 [33280/60000 (55%)]\tLoss: 102.839523\n",
            "Train Epoch: 19 [35840/60000 (60%)]\tLoss: 102.606964\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 103.562988\n",
            "Train Epoch: 19 [40960/60000 (68%)]\tLoss: 105.058876\n",
            "Train Epoch: 19 [43520/60000 (72%)]\tLoss: 104.712967\n",
            "Train Epoch: 19 [46080/60000 (77%)]\tLoss: 102.675102\n",
            "Train Epoch: 19 [48640/60000 (81%)]\tLoss: 103.926071\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 105.778770\n",
            "Train Epoch: 19 [53760/60000 (90%)]\tLoss: 103.778076\n",
            "Train Epoch: 19 [56320/60000 (94%)]\tLoss: 104.823212\n",
            "Train Epoch: 19 [58880/60000 (98%)]\tLoss: 99.640015\n",
            "====> Epoch: 19 Average loss: 104.1920\n",
            "====> Test set loss: 103.9408\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 107.348557\n",
            "Train Epoch: 20 [2560/60000 (4%)]\tLoss: 103.979103\n",
            "Train Epoch: 20 [5120/60000 (9%)]\tLoss: 100.073395\n",
            "Train Epoch: 20 [7680/60000 (13%)]\tLoss: 101.434319\n",
            "Train Epoch: 20 [10240/60000 (17%)]\tLoss: 106.298370\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 99.086075\n",
            "Train Epoch: 20 [15360/60000 (26%)]\tLoss: 99.403351\n",
            "Train Epoch: 20 [17920/60000 (30%)]\tLoss: 102.771736\n",
            "Train Epoch: 20 [20480/60000 (34%)]\tLoss: 102.061676\n",
            "Train Epoch: 20 [23040/60000 (38%)]\tLoss: 104.545547\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 103.557213\n",
            "Train Epoch: 20 [28160/60000 (47%)]\tLoss: 105.221207\n",
            "Train Epoch: 20 [30720/60000 (51%)]\tLoss: 102.643234\n",
            "Train Epoch: 20 [33280/60000 (55%)]\tLoss: 102.866577\n",
            "Train Epoch: 20 [35840/60000 (60%)]\tLoss: 107.674759\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 106.897614\n",
            "Train Epoch: 20 [40960/60000 (68%)]\tLoss: 99.935509\n",
            "Train Epoch: 20 [43520/60000 (72%)]\tLoss: 105.832596\n",
            "Train Epoch: 20 [46080/60000 (77%)]\tLoss: 105.237328\n",
            "Train Epoch: 20 [48640/60000 (81%)]\tLoss: 106.631516\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 102.748039\n",
            "Train Epoch: 20 [53760/60000 (90%)]\tLoss: 106.884918\n",
            "Train Epoch: 20 [56320/60000 (94%)]\tLoss: 104.314255\n",
            "Train Epoch: 20 [58880/60000 (98%)]\tLoss: 104.020325\n",
            "====> Epoch: 20 Average loss: 104.0594\n",
            "====> Test set loss: 103.8369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdR-Y87CVlfh",
        "colab_type": "text"
      },
      "source": [
        "italicized text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntb-Xo0aba04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}